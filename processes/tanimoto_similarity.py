"""
Calculate Tanimoto similarity metrics for SMILES generated by beam search.

This module reads each epoch's SMILES files from the beam_search directory,
calculates Tanimoto similarity against a base molecule, and produces a summary
of similarity statistics for each epoch.
"""
import os
import glob
import pandas as pd
import numpy as np
from rdkit import Chem
from rdkit import DataStructs
from rdkit.Chem import AllChem
from rdkit import rdBase
from loguru import logger
import re

# Suppress RDKit unnecessary output
rdBase.DisableLog('rdApp.*')

# Import configuration
from configs.path_config import exp_beam_search_path


def get_tanimoto_similarity(smile1: str, smile2: str) -> float:
    """
    Calculates tanimoto similarity between 2 molecules

    Args:
        smile1 (str): smile structure of 1st molecule
        smile2 (str): smile structure of 2nd molecule

    Returns:
        float: _description_
    """
    query = Chem.MolFromSmiles(smile1)
    fp1 = Chem.RDKFingerprint(query)
    
    query2 = Chem.MolFromSmiles(smile2)
    fp2 = Chem.RDKFingerprint(query2)
    return DataStructs.TanimotoSimilarity(fp1,fp2)


def get_top_epochs():
    base_molecule =  'CC[C@H](C)[C@@H](C(=O)N[C@@H](C)C(=O)N[C@@H](CC1=CNC2=CC=CC=C21)C(=O)N[C@@H](CC(C)C)C(=O)N[C@@H](C(C)C)C(=O)N[C@@H](CCCNC(=N)N)C(=O)NCC(=O)N[C@@H](CCCNC(=N)N)C(=O)NCC(=O)O)NC(=O)[C@H](CC3=CC=CC=C3)NC(=O)[C@H](CCC(=O)O)NC(=O)[C@H](CCCCNC(=O)COCCOCCNC(=O)COCCOCCNC(=O)CC[C@H](C(=O)O)NC(=O)CCCCCCCCCCCCCCCCC(=O)O)NC(=O)[C@H](C)NC(=O)[C@H](C)NC(=O)[C@H](CCC(=O)N)NC(=O)CNC(=O)[C@H](CCC(=O)O)NC(=O)[C@H](CC(C)C)NC(=O)[C@H](CC4=CC=C(C=C4)O)NC(=O)[C@H](CO)NC(=O)[C@H](CO)NC(=O)[C@H](C(C)C)NC(=O)[C@H](CC(=O)O)NC(=O)[C@H](CO)NC(=O)[C@H]([C@@H](C)O)NC(=O)[C@H](CC5=CC=CC=C5)NC(=O)[C@H]([C@@H](C)O)NC(=O)CNC(=O)[C@H](CCC(=O)O)NC(=O)C(C)(C)NC(=O)[C@H](CC6=CN=CN6)N'
    return base_molecule


def calculate_tanimoto_similarity(smiles_list, base_smiles):
    """Calculate Tanimoto similarity between a list of SMILES and a base molecule.
    
    Args:
        smiles_list (list): List of SMILES strings to compare
        base_smiles (str): SMILES of the base molecule
        
    Returns:
        list: List of similarity scores
    """
    # Convert base molecule to RDKit molecule
    base_mol = Chem.MolFromSmiles(base_smiles)
    if base_mol is None:
        raise ValueError(f"Invalid base SMILES: {base_smiles}")
    
    # Calculate fingerprint for base molecule
    base_fp = Chem.RDKFingerprint(base_mol)
    
    # Calculate similarities
    similarities = []
    valid_mols = []
    
    for smiles in smiles_list:
        try:
            mol = Chem.MolFromSmiles(smiles)
            if mol is None:
                continue  # Skip invalid SMILES
                
            fp = Chem.RDKFingerprint(mol)
            similarity = DataStructs.TanimotoSimilarity(base_fp, fp)
            similarities.append(similarity)
            valid_mols.append(mol)
        except Exception as e:
            logger.warning(f"Error processing SMILES {smiles}: {str(e)}")
            continue
        
    return similarities, valid_mols


def process_epoch_file(filepath, base_smiles):
    """Process a single epoch file and calculate similarity statistics.
    
    Args:
        filepath (str): Path to the epoch SMILES file
        base_smiles (str): SMILES of the base molecule
        
    Returns:
        dict: Dictionary containing similarity statistics
    """
    # Extract epoch number from filename
    filename = os.path.basename(filepath)
    match = re.search(r'epoch_(\d+)_SMILES\.txt', filename)
    if match:
        epoch_num = int(match.group(1))
    else:
        # Fallback to just the filename if epoch number can't be extracted
        epoch_num = os.path.splitext(filename)[0]
    
    # Read SMILES from file
    with open(filepath, 'r') as f:
        smiles_list = [line.strip() for line in f if line.strip()]
    
    # Calculate similarities
    similarities, valid_mols = calculate_tanimoto_similarity(smiles_list, base_smiles)
    
    # Calculate statistics
    if similarities:
        result = {
            'epoch': epoch_num,
            'total_smiles': len(smiles_list),
            'valid_smiles': len(similarities),
            'min_similarity': min(similarities),
            'max_similarity': max(similarities),
            'avg_similarity': np.mean(similarities),
            'median_similarity': np.median(similarities),
            'std_similarity': np.std(similarities)
        }
    else:
        # Handle the case where no valid molecules were found
        result = {
            'epoch': epoch_num,
            'total_smiles': len(smiles_list),
            'valid_smiles': 0,
            'min_similarity': np.nan,
            'max_similarity': np.nan,
            'avg_similarity': np.nan,
            'median_similarity': np.nan,
            'std_similarity': np.nan
        }
    
    return result, similarities, valid_mols


def generate_tanimoto_summary(base_smiles, save_dir=None):
    """Generate Tanimoto similarity summary for all epoch files.
    
    Args:
        base_smiles (str): SMILES of the base molecule
        save_dir (str, optional): Directory to save results
        
    Returns:
        pd.DataFrame: DataFrame with similarity statistics for each epoch
    """
    # Use beam_search path from config if save_dir is not provided
    if save_dir is None:
        save_dir = exp_beam_search_path

    # Ensure the directory exists
    os.makedirs(save_dir, exist_ok=True)
    
    # Find all epoch SMILES files
    epoch_files = sorted(glob.glob(os.path.join(save_dir, "epoch_*_SMILES.txt")))
    
    if not epoch_files:
        logger.error(f"No epoch SMILES files found in {save_dir}")
        return None
    
    logger.info(f"Found {len(epoch_files)} epoch files")
    
    # Process each file
    results = []
    all_similarities = {}
    
    for filepath in epoch_files:
        logger.info(f"Processing {os.path.basename(filepath)}...")
        
        try:
            result, similarities, valid_mols = process_epoch_file(filepath, base_smiles)
            results.append(result)
            
            # Store similarities for later visualization
            epoch_num = result['epoch']
            all_similarities[epoch_num] = similarities
            
            logger.info(f"Epoch {epoch_num}: Avg similarity = {result['avg_similarity']:.4f}, "
                       f"Valid: {result['valid_smiles']}/{result['total_smiles']}")
        
        except Exception as e:
            logger.error(f"Error processing {filepath}: {str(e)}")
    
    if not results:
        logger.error("No results generated. Check for errors above.")
        return None
    
    # Create DataFrame from results
    results_df = pd.DataFrame(results)
    
    # Sort by epoch number
    results_df = results_df.sort_values('epoch').reset_index(drop=True)
    
    # Save results to CSV
    output_file = os.path.join(save_dir, "tanimoto_similarity_summary.csv")
    results_df.to_csv(output_file, index=False)
    logger.info(f"Saved summary to {output_file}")
    
    return results_df


def tanimoto_similarity(base_smiles=None):
    """Main function to run tanimoto similarity analysis.
    
    Args:
        base_smiles (str, optional): SMILES of the base molecule
        
    Returns:
        bool: True if analysis was successful, False otherwise
    """
    logger.info("Starting Tanimoto similarity analysis")
    
    # Default base smiles if not provided
    if base_smiles is None:
        # Use the existing default from the original function
        base_smiles = get_top_epochs()
        logger.info(f"Using default base molecule from get_top_epochs()")
    
    try:
        # Check if the base SMILES is valid
        base_mol = Chem.MolFromSmiles(base_smiles)
        if base_mol is None:
            logger.error(f"Invalid base molecule SMILES: {base_smiles}")
            return False
        
        # Generate summary
        results_df = generate_tanimoto_summary(base_smiles)
        if results_df is not None:
            logger.info("Tanimoto similarity analysis completed successfully")
            return True
        else:
            logger.error("Failed to generate Tanimoto similarity summary")
            return False

    except Exception as e:
        logger.error(f"Error in Tanimoto similarity analysis: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return False


if __name__ == "__main__":
    # Example usage
    # Provide a base molecule SMILES or let it use the default
    tanimoto_similarity()
